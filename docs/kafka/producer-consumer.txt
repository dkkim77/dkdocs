26.0 Windows Linux 환경 설치.
- WSL 설치. Windows Terminal 도 설치(멀티 탭 지원)
- apt 갱신 
  sudo apt update
  sudo apt -y upgrade 
- java 설치.
  sudo apt install default-jdk  
- WSL Kafka 에서 Windows MariaDB 로 통신
  VM 이므로 telnet localhost 330 6은 접속 불능이고 telnet DESKTOP-SCB21V2.local 3306 으로 해야 접속 가능  
  
26. Zookeeper-Kafka 
	
	0. 구조도	
	            zookeeper-1 (2888) ------ zookeeper-2 (2888) ------ zookeeper-3 (2888)
	               (2181)					(2181)						(2181)
	                 ^                         ^                          ^
	                 |                         |                          |
	               kafka-1                  kafka-2                    kafka-3
	               (9092)
	                 ^
	                 |
	               Pub/Sub
	               
	26.1 다운로드 
	wget https://archive.apache.org/dist/kafka/3.2.0/kafka_2.13-3.2.0.tgz
	tar xvf kafka_2.13-3.2.0.tgz

	26.2 주키퍼 
	- 주키퍼 클러스터 설정 : 한대의 leader 와 다수의 follower 로 구성.
	[zookeeper.properties]
		# 주키퍼 리스너 포트 
		clientPort=2181
		# tick 시간 설정
		tickTime=3000 (ms)
		# follower 가 leader 와 연결 시도 제한 횟수. 
		initLimit=10 (단위:tickTime. 1tick 은 3000ms)							
		# follower 가 leader 와 연결된 후 동기화되기 위한 제한 횟수 
		syncLimit=5 
				
		# 주키퍼 앙상블 (클러스터 내 노드들의 상호 연결)
		# server.<myid>=<호스트명>:<포트1>:<포트2> - port1:동기화 포트, port2:leader 선출용 포트 
		server.1=unchart77-01:2888:3888
		server.2=unchart78-02:2888:3888
		server.3=unchart79-03:2888:3888
	- 실행,종료,테스트
	zookeeper-server-start.sh -daemon ../config/zookeeper.properties
	zookeeper-server-stop.sh
	zookeeper-shell.sh localhost:2181[enter]
	ls /[enter]
	create /zookeeper/test welcome => 키/값 생성
	get /zookeeper/test            => 조회
	set /zookeeper/test bye        => 수정 
	delete /zookeeper/test         => 삭제
	-----------------------------------------
				For Windows
	-----------------------------------------		
	zookeeper-server-start.bat ../../config/zookeeper.properties		
	-----------------------------------------
			
	26.2 카프카 
	
	26.2.1 설치 및 기본 사용 
	- 설정
	profile 에 등록 : export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"	
	[config/server.properties]	
		advertised.listeners=PLAINTEXT://ec2-3-38-39-80.ap-northeast-2.compute.amazonaws.com:9092으로 수정		
		# kafka 의 brokerId 설정.  The id of the broker. This must be set to a unique integer for each broker.
		broker.id=1 <서버별로 정한 BrokerId>
		# broker id 를 자동으로 부여할 경우 broker.id.generation.enable 를 true 로 설정
		broker.id.generation.enable=false	
		zookeeper.connect=unchart77-01:2181,unchart78-02:2181,unchart79-03:2181	

	- 실행,종료
	kafka-server-start.sh -daemon ../config/server.properties
	kafka-server-stop.sh
	-----------------------------------------
				For Windows
	-----------------------------------------				
	kafka-server-start.bat ../../config/server.properties		
	-----------------------------------------
	# topic 목록 조회
	kafka-topics --bootstrap-server localhost:9092 --list
	
	# topic 생성(Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide)
	kafka-topics --bootstrap-server localhost:9092 --create --topic TOPIC-TEST 
	kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic TOPIC-TEST  
	
	# topic 에 쓰기 
	kafka-console-producer.sh --bootstrap-server localhost:9092 --topic TOPIC-TEST 
	> 멈추려면 Ctrl-C
	(
		클러스터일 경우 : kafka-console-producer.sh --broker-list broker1:9092,broker2:9092,broker3:9092 --topic TOPIC-TEST
		설명 : 브로거 리스트는 producer 가 클러스터에 처음 접속할 때의 정보로 이용된다. 접속 후 클러스터의 정보를 얻기 때문에 전체를 지정할 필요는 없지만 
		      장애 등으로 특정 서버에 접속할 수 없을 경우 다른 서버에 접속을 시도한다. => 각 서버에 송신하는게 아니라 클러스터에 송신하면 ISR(In-sync replicas) 끼리 복제된다는 의미겠지?
	)
	
	# topic 에서 읽기(topic 이 비워지지 않음)	
	kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic TOPIC-TEST
	(
		클러스터일 경우 : kafka-console-consumer.sh --bootstrap-server broker1:9092,broker2:9092,broker3:9092 --topic TOPIC-TEST
	)
	
	# consumer 그룹 목록 조회 
	kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list 
	
	# consumer 그룹 상세 조회 
	kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group TOPIC-TEST-CONSUMER-GRP1 --describe  
	
	# offset 변경 관련 : --reset-offsets <sub-command> 
	kafka-consumer-groups.sh --bootstrap-server localhost:9092 --topic TOPIC-TEST --group TOPIC-TEST-CONSUMER-GRP2 --execute --reset-offsets --to-offset  
	--execute : 생략할 경우 dry run (실제 반영 안되고 예정 결과만 보여줌)
	-- sub command
		to-datetime <String: datetime>	특정 시간대의 offset으로 되돌린다. Format 'YYYY-MM-DDTHH:mm:SS.sss'
		to-earliest	처리할 수 있는 가장 처음 시간으로 되돌린다.
		to-latest	가장 최근의 offset으로 변경한다.
		shift-by <Long: number-of offsets>	현재 위치부터 설정한 n값에 따라 offset 위치를 변경한다. n값은 양수, 음수 모두 사용 가능하다.
		from-file	CSV 파일에 설정되어 있는 각 offset 위치로 변경한다.(아마 그룹 전체를 변경할 때에 사용할 듯)
		to-current	현재 offset 위치로 변경한다.
		by-duration	현재 시간 기준으로 옵션에 작성한 시간 기준별로 offset을 변경한다. Format: 'PnDTnHnMnS'
		to-offset	설정한 offset위치로 변경한다.
		
	26.2.2 Kafka Connect 
	구성
	    
	    MySQL      --> debezium mysql        ----> ################### ----> ElasticSearch Connector ----> ElasticSearch
	                                         ----> ################### ----> InfiniSpan Connector    ----> InfiniSpan                         
	    PostgreSQL --> debezium postgresql   ----> ################### ---->     JDBC Connector      ----> Data warehouse
	    
	    --------------------------------------------------------------------------------------------------------
	      DB       connect with source connectors      Apache Kafka        Connect with sink connectors
	    
	connect   : Connector 를 동작하게 하는 프로세스. REST api 를 이용해서 Connector 를 등록 및 사용. 
	Connector : Data Source 의 데이터를 데이터를 처리하는 코드가 있는 jar
	- Source Connector : Producer 의 역할
	- Sink Connector   : Consumer 의 역할
	* connect 는 standalone 과 distribute 모드가 있다. distribute 모드는 여러개의 connect 를 clustering 하여 사용하는 모드.
	  